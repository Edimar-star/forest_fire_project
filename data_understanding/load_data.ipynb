{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUw1D4CkTx9v"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wJH_9Rekj_La"
      },
      "outputs": [],
      "source": [
        "from netCDF4 import Dataset\n",
        "from urllib import request\n",
        "from datetime import date\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import rasterio\n",
        "import zipfile\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYviqtW0GDuz"
      },
      "source": [
        "# Root directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "aDRFhZXFGFhi"
      },
      "outputs": [],
      "source": [
        "root_directory_path = \"./datasets\"\n",
        "\n",
        "if not os.path.exists(root_directory_path):\n",
        "  os.makedirs(root_directory_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-GzYylUf8lp"
      },
      "source": [
        "# Forest Fire Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV3d7orqXusp"
      },
      "source": [
        "Near real-time (NRT) Moderate Resolution Imaging Spectroradiometer (MODIS) Thermal Anomalies / Fire locations - Collection 61 processed by NASA's Land, Atmosphere Near real-time Capability for EO (LANCE) Fire Information for Resource Management System (FIRMS), using swath products (MOD14/MYD14) rather than the tiled MOD14A1 and MYD14A1 products. The thermal anomalies / active fire represent the center of a 1 km pixel that is flagged by the MODIS MOD14/MYD14 Fire and Thermal Anomalies algorithm (Giglio 2003) as containing one or more fires within the pixel. This is the most basic fire product in which active fires and other thermal anomalies, such as volcanoes, are identified.\n",
        "\n",
        "For more information [here](https://www.earthdata.nasa.gov/learn/find-data/near-real-time/firms/mcd14dl-nrt#ed-firms-attributes) \\\\\n",
        "Download dataset [here](https://firms.modaps.eosdis.nasa.gov/data/download/DL_FIRE_SV-C2_438634.zip)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73bVkXzfo2mC"
      },
      "outputs": [],
      "source": [
        "# Datos desde el 2002 hasta 2011\n",
        "remote_url = \"https://firms.modaps.eosdis.nasa.gov/data/download/DL_FIRE_M-C61_438863.zip\"\n",
        "local_file = f\"{root_directory_path}/forest_fire_Colombia_2002_2011.zip\"\n",
        "local_csv_2002_2011 = f\"{root_directory_path}/forest_fire_Colombia_2002_2011.csv\"\n",
        "request.urlretrieve(remote_url, local_file)\n",
        "\n",
        "with zipfile.ZipFile(local_file, 'r') as zip_ref:\n",
        "  zip_ref.extractall(root_directory_path)\n",
        "\n",
        "os.remove(local_file)\n",
        "os.remove(f\"{root_directory_path}/Readme.txt\")\n",
        "os.rename(f\"{root_directory_path}/fire_archive_M-C61_438863.csv\", local_csv_2002_2011)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5smK7yg-frn8"
      },
      "outputs": [],
      "source": [
        "# Datos desde el 2012 hasta 2022\n",
        "remote_url = \"https://firms.modaps.eosdis.nasa.gov/data/download/DL_FIRE_SV-C2_438634.zip\"\n",
        "local_file = f\"{root_directory_path}/forest_fire_Colombia_2012_2022.zip\"\n",
        "local_csv_2012_2022 = f\"{root_directory_path}/forest_fire_Colombia_2012_2022.csv\"\n",
        "request.urlretrieve(remote_url, local_file)\n",
        "\n",
        "with zipfile.ZipFile(local_file, 'r') as zip_ref:\n",
        "  zip_ref.extractall(root_directory_path)\n",
        "\n",
        "os.remove(local_file)\n",
        "os.remove(f\"{root_directory_path}/Readme.txt\")\n",
        "os.remove(f\"{root_directory_path}/fire_nrt_SV-C2_438634.csv\")\n",
        "os.rename(f\"{root_directory_path}/fire_archive_SV-C2_438634.csv\", local_csv_2012_2022)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "772Hf263qyvk"
      },
      "outputs": [],
      "source": [
        "# Datos desde el 2019 hasta 2024\n",
        "remote_url = \"https://firms.modaps.eosdis.nasa.gov/data/download/DL_FIRE_J1V-C2_438632.zip\"\n",
        "local_file = f\"{root_directory_path}/forest_fire_Colombia_2019_2024.zip\"\n",
        "local_csv_2019_2024 = f\"{root_directory_path}/forest_fire_Colombia_2019_2024.csv\"\n",
        "request.urlretrieve(remote_url, local_file)\n",
        "\n",
        "with zipfile.ZipFile(local_file, 'r') as zip_ref:\n",
        "  zip_ref.extractall(root_directory_path)\n",
        "\n",
        "os.remove(local_file)\n",
        "os.remove(f\"{root_directory_path}/Readme.txt\")\n",
        "os.rename(f\"{root_directory_path}/fire_nrt_J1V-C2_438632.csv\", local_csv_2019_2024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEy6xY7AsiWs"
      },
      "outputs": [],
      "source": [
        "df_csv_2002_2011 = pd.read_csv(local_csv_2002_2011)\n",
        "df_csv_2012_2022 = pd.read_csv(local_csv_2012_2022)\n",
        "df_csv_2019_2024 = pd.read_csv(local_csv_2019_2024)\n",
        "\n",
        "df_csv_2002_2011['acq_date'] = pd.to_datetime(df_csv_2002_2011['acq_date'])\n",
        "df_csv_2012_2022['acq_date'] = pd.to_datetime(df_csv_2012_2022['acq_date'])\n",
        "df_csv_2019_2024['acq_date'] = pd.to_datetime(df_csv_2019_2024['acq_date'])\n",
        "\n",
        "date_min_2019_2024 = df_csv_2019_2024['acq_date'].min()\n",
        "df_csv_2012_2022 = df_csv_2012_2022[df_csv_2012_2022['acq_date'] < date_min_2019_2024]\n",
        "\n",
        "forest_fire_path = f\"{root_directory_path}/forest_fire_Colombia.csv\"\n",
        "df_forest_fire = pd.concat([df_csv_2002_2011, df_csv_2012_2022, df_csv_2019_2024])\n",
        "df_forest_fire.sort_values(by=\"acq_date\")\n",
        "df_forest_fire.to_csv(forest_fire_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiUCeVT7tahz"
      },
      "outputs": [],
      "source": [
        "os.remove(local_csv_2002_2011)\n",
        "os.remove(local_csv_2012_2022)\n",
        "os.remove(local_csv_2019_2024)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAV0R_YDgBen"
      },
      "source": [
        "# NDVI Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6HRYWtOZk1E"
      },
      "source": [
        "This dataset contains dekadal NDVI indicators computed from NASA's Moderate Resolution Imaging Spectroradiometer (MODIS) collection 6.1 from the Aqua and Terra satellite aggregated by sub-national administrative units.\n",
        "\n",
        "Included indicators are (for each dekad):\n",
        "\n",
        "- 10 day NDVI (vim)\n",
        "- NDVI long term average (vim_lta)\n",
        "- 10 day NDVI anomaly [%] (viq)\n",
        "\n",
        "The administrative units used for aggregation are based on WFP data and contain a Pcode reference attributed to each unit. The number of input pixels used to create the aggregates, is provided in the n_pixels column.\n",
        "\n",
        "More information [here](https://data.humdata.org/dataset/col-ndvi-subnational)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ySdoL5yfuTE",
        "outputId": "61d2101a-2b88-4d8a-c363-d653ca76e69b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./datasets/ndvi_Colombia.csv', <http.client.HTTPMessage at 0x7d0c596c2290>)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "remote_url = \"https://data.humdata.org/dataset/7f2ba5ba-8df1-41cf-ab18-fc1da928a1e5/resource/c06298d9-0d4d-4e40-aecc-abc1da75dc4d/download/col-ndvi-adm2-full.csv\"\n",
        "local_file = f\"{root_directory_path}/ndvi_Colombia.csv\"\n",
        "request.urlretrieve(remote_url, local_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OrmyxAWgPpT"
      },
      "source": [
        "# Global Climate Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOuBpgxjfxVp"
      },
      "source": [
        "TerraClimate is a dataset of monthly climate and climatic water balance for global terrestrial surfaces from 1958-2019. These data provide important inputs for ecological and hydrological studies at global scales that require high spatial resolution and time-varying data. All data have monthly temporal resolution and a ~4-km (1/24th degree) spatial resolution. The data cover the period from 1958-2020. We plan to update these data periodically (annually).\n",
        "\n",
        "More information [here](https://www.climatologylab.org/terraclimate.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AG6mJ_FK2BZ"
      },
      "outputs": [],
      "source": [
        "def check_latlon_bounds(lat,lon,lat_index,lon_index,lat_target,lon_target):\n",
        "    #check final indices are in right bounds\n",
        "    if(lat[lat_index]>lat_target):\n",
        "        if(lat_index!=0):\n",
        "            lat_index = lat_index - 1\n",
        "    if(lat[lat_index]<lat_target):\n",
        "        if(lat_index!=len(lat)):\n",
        "            lat_index = lat_index +1\n",
        "    if(lon[lon_index]>lon_target):\n",
        "        if(lon_index!=0):\n",
        "            lon_index = lon_index - 1\n",
        "    if(lon[lon_index]<lon_target):\n",
        "        if(lon_index!=len(lon)):\n",
        "            lon_index = lon_index + 1\n",
        "\n",
        "    return [lat_index, lon_index]\n",
        "\n",
        "def get_data_country(df_modis, varnames):\n",
        "  values = {varname: [] for varname in [\"date\", \"lat\", \"lon\"] + varnames}\n",
        "  df_modis[\"acq_date\"] = pd.to_datetime(df_modis[\"acq_date\"])\n",
        "  df_modis = df_modis.sort_values(by=\"acq_date\")\n",
        "  year_min, year_max = df_modis['acq_date'].min().year, df_modis['acq_date'].max().year\n",
        "\n",
        "  for year in range(year_min, 2024):\n",
        "    print(f\"Descargando datos del año {year}: [ \", end=\"\")\n",
        "    df = df_modis[df_modis[\"acq_date\"] <= pd.to_datetime(f\"{year}-12-31\")]\n",
        "    df = df[pd.to_datetime(f\"{year}-01-01\") <= df[\"acq_date\"]]\n",
        "\n",
        "    date_values, lat_values, lon_values = df['acq_date'], df['latitude'], df['longitude']\n",
        "    lat_min, lon_min = lat_values.min(), lon_values.min()\n",
        "    lat_max, lon_max = lat_values.max(), lon_values.max()\n",
        "\n",
        "    values['date'] += [str(date_.date()) for date_ in date_values]\n",
        "    values['lat'] += list(lat_values.values)\n",
        "    values['lon'] += list(lon_values.values)\n",
        "    date_values = (date_values - pd.to_datetime(\"1900-01-01\")).dt.days\n",
        "\n",
        "    for varname in varnames:\n",
        "      print(f\"{varname} \", end=\"\")\n",
        "      pathname = f\"http://thredds.northwestknowledge.net:8080/thredds/dodsC/TERRACLIMATE_ALL/data/TerraClimate_{varname}_{year}.nc\"\n",
        "      filehandle = Dataset(pathname, 'r', format=\"NETCDF4\")\n",
        "\n",
        "      # subset in space (lat/lon)\n",
        "      lathandle = filehandle.variables['lat']\n",
        "      lonhandle = filehandle.variables['lon']\n",
        "      lat=lathandle[:]\n",
        "      lon=lonhandle[:]\n",
        "\n",
        "      # find indices of target lat/lon/day\n",
        "      lat_index_min = (np.abs(lat-lat_min)).argmin()\n",
        "      lat_index_max = (np.abs(lat-lat_max)).argmin()\n",
        "      lon_index_min = (np.abs(lon-lon_min)).argmin()\n",
        "      lon_index_max = (np.abs(lon-lon_max)).argmin()\n",
        "\n",
        "      [lat_index_min,lon_index_min] = check_latlon_bounds(lat, lon, lat_index_min, lon_index_min, lat_min, lon_min)\n",
        "      [lat_index_max,lon_index_max] = check_latlon_bounds(lat, lon, lat_index_max, lon_index_max, lon_max, lon_max)\n",
        "\n",
        "      if(lat_index_min>lat_index_max):\n",
        "          lat_index_range = range(lat_index_max, lat_index_min+1)\n",
        "      else:\n",
        "          lat_index_range = range(lat_index_min, lat_index_max+1)\n",
        "      if(lon_index_min>lon_index_max):\n",
        "          lon_index_range = range(lon_index_max, lon_index_min+1)\n",
        "      else:\n",
        "          lon_index_range = range(lon_index_min, lon_index_max+1)\n",
        "\n",
        "      lat=lat[lat_index_range]\n",
        "      lon=lon[lon_index_range]\n",
        "\n",
        "      # subset in time\n",
        "      timehandle=filehandle.variables['time']\n",
        "      time=timehandle[:]\n",
        "      time_min = (date(year,1,1)-date(1900,1,1)).days\n",
        "      time_max = (date(year,12,31)-date(1900,1,1)).days\n",
        "      time_index_min = (np.abs(time-time_min)).argmin()\n",
        "      time_index_max = (np.abs(time-time_max)).argmin()\n",
        "      time_index_range = range(time_index_min, time_index_max+1)\n",
        "      time = timehandle[time_index_range]\n",
        "\n",
        "      # subset data\n",
        "      datahandle = filehandle.variables[varname]\n",
        "      data = datahandle[time_index_range, lat_index_range, lon_index_range]\n",
        "\n",
        "      # Indexes\n",
        "      time_indexes = np.abs(time[:, np.newaxis] - date_values.to_numpy()).argmin(axis=0)\n",
        "      lat_indexes = np.abs(lat[:, np.newaxis] - lat_values.to_numpy()).argmin(axis=0)\n",
        "      lon_indexes = np.abs(lon[:, np.newaxis] - lon_values.to_numpy()).argmin(axis=0)\n",
        "      values[varname] += list(data[time_indexes, lat_indexes, lon_indexes])\n",
        "    print(\"]\")\n",
        "  return values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kchkE1GXQqhk",
        "outputId": "294adf7e-b6f5-40f9-e4ba-2db307cfa308"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Descargando datos del año 2002: [ ws vpd vap tmin tmax swe srad soil q ppt pet def aet PDSI ]\n",
            "Descargando datos del año 2003: [ ws vpd vap tmin tmax swe srad soil q ppt pet def aet PDSI ]\n",
            "Descargando datos del año 2004: [ ws vpd vap tmin tmax swe srad soil q ppt pet def aet PDSI ]\n",
            "Descargando datos del año 2005: [ ws vpd vap tmin tmax swe srad soil q ppt pet def aet PDSI ]\n",
            "Descargando datos del año 2006: [ ws vpd vap tmin tmax swe srad soil q ppt pet def aet PDSI ]\n",
            "Descargando datos del año 2007: [ ws vpd vap tmin tmax swe srad soil q ppt pet def aet PDSI ]\n",
            "Descargando datos del año 2008: [ ws vpd vap tmin tmax swe srad soil q ppt pet def aet PDSI ]\n",
            "Descargando datos del año 2009: [ ws vpd vap tmin tmax swe srad soil q ppt pet def aet PDSI ]\n",
            "Descargando datos del año 2010: [ ws vpd vap tmin tmax swe srad soil q ppt pet def aet PDSI ]\n",
            "Descargando datos del año 2011: [ ws vpd vap tmin tmax swe srad soil q ppt pet def aet PDSI ]\n",
            "Descargando datos del año 2012: [ ws vpd vap tmin tmax swe srad soil q ppt pet def aet PDSI ]\n",
            "Descargando datos del año 2013: [ ws vpd vap tmin tmax swe srad soil q ppt pet def aet PDSI ]\n",
            "Descargando datos del año 2014: [ ws vpd vap tmin tmax swe srad soil q ppt pet def aet PDSI ]\n",
            "Descargando datos del año 2015: [ ws vpd vap tmin tmax swe srad soil q ppt pet def aet PDSI ]\n",
            "Descargando datos del año 2016: [ ws vpd vap tmin tmax swe srad soil q ppt pet def aet PDSI ]\n",
            "Descargando datos del año 2017: [ ws vpd vap tmin tmax swe srad soil q ppt pet def aet PDSI ]\n",
            "Descargando datos del año 2018: [ ws vpd vap tmin tmax swe srad soil q ppt pet def aet PDSI ]\n",
            "Descargando datos del año 2019: [ ws vpd vap tmin tmax swe srad soil q ppt pet def aet PDSI ]\n",
            "Descargando datos del año 2020: [ ws vpd vap tmin tmax swe srad soil q ppt pet def aet PDSI ]\n",
            "Descargando datos del año 2021: [ ws vpd vap tmin tmax swe srad soil q ppt pet def aet PDSI ]\n",
            "Descargando datos del año 2022: [ ws vpd vap tmin tmax swe srad soil q ppt pet def aet PDSI ]\n",
            "Descargando datos del año 2023: [ ws vpd vap tmin tmax swe srad soil q ppt pet def aet PDSI ]\n"
          ]
        }
      ],
      "source": [
        "varnames = [\"ws\", \"vpd\", \"vap\", \"tmin\", \"tmax\", \"swe\", \"srad\", \"soil\", \"q\", \"ppt\", \"pet\", \"def\", \"aet\", \"PDSI\"]\n",
        "global_climate_path = f\"{root_directory_path}/global_climate_Colombia.csv\"\n",
        "values = get_data_country(df_forest_fire, varnames)\n",
        "df_global_climate = pd.DataFrame(values)\n",
        "df_global_climate.to_csv(global_climate_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E---mq6HTxAs"
      },
      "source": [
        "# Population Density Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHjz39TQaj70"
      },
      "source": [
        "Estimated population density per grid-cell. The dataset is available to download in Geotiff and ASCII XYZ format at a resolution of 30 arc (approximately 1km at the equator). The projection is Geographic Coordinate System, WGS84. The units are number of people per square kilometre based on country totals adjusted to match the corresponding official United Nations population estimates that have been prepared by the Population Division of the Department of Economic and Social Affairs of the United Nations Secretariat (2019 Revision of World Population Prospects). The mapping approach is Random Forest-based dasymetric redistribution.\n",
        "\n",
        "More information [here](https://hub.worldpop.org/geodata/summary?id=45716)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oxSSg6lTzRZ"
      },
      "outputs": [],
      "source": [
        "for year in range(2002, 2021):\n",
        "  remote_url = f\"https://data.worldpop.org/GIS/Population_Density/Global_2000_2020_1km/{year}/COL/col_pd_{year}_1km_ASCII_XYZ.zip\"\n",
        "  local_file = f\"{root_directory_path}/population_density_Colombia_{year}.zip\"\n",
        "  request.urlretrieve(remote_url, local_file)\n",
        "\n",
        "  with zipfile.ZipFile(local_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(root_directory_path)\n",
        "  os.remove(local_file)\n",
        "\n",
        "local_file = f\"{root_directory_path}/col_pd_2020_1km_ASCII_XYZ.csv\"\n",
        "df_temp = pd.read_csv(local_file)\n",
        "for year in range(2020, 2024):\n",
        "  df_temp.to_csv(f\"{root_directory_path}/col_pd_{year}_1km_ASCII_XYZ.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dW0EwdsazoZ"
      },
      "outputs": [],
      "source": [
        "lat_values, lon_values = df_forest_fire['latitude'], df_forest_fire['longitude']\n",
        "lat_min, lat_max = lat_values.min(), lat_values.max()\n",
        "lon_min, lon_max = lon_values.min(), lon_values.max()\n",
        "pd_values = {\"lat\": lat_values.to_numpy(), \"lon\": lon_values.to_numpy()}\n",
        "df_population_density = pd.DataFrame({'longitude': [], 'latitude': []})\n",
        "\n",
        "# Unimos los datasets\n",
        "for year in range(2002, 2024):\n",
        "  df_pd = pd.read_csv(f\"{root_directory_path}/col_pd_{year}_1km_ASCII_XYZ.csv\")\n",
        "  df_pd.rename(columns={'X': 'longitude', 'Y': 'latitude', 'Z': f'pd_{year}'}, inplace=True)\n",
        "  df_population_density = pd.merge(df_population_density, df_pd, on=['longitude', 'latitude'], how='outer')\n",
        "\n",
        "# Filtramos las latitudes\n",
        "df_population_density.sort_values(by=\"latitude\")\n",
        "df_population_density = df_population_density[lat_min <= df_population_density['latitude']]\n",
        "df_population_density = df_population_density[df_population_density['latitude'] <= lat_max]\n",
        "\n",
        "# Filtramos las longitudes\n",
        "df_population_density.sort_values(by=\"longitude\")\n",
        "df_population_density = df_population_density[lon_min <= df_population_density['longitude']]\n",
        "df_population_density = df_population_density[df_population_density['longitude'] <= lon_max]\n",
        "df_population_density.to_csv(f\"{root_directory_path}/population_density_Colombia.csv\", index=False)\n",
        "\n",
        "# Eliminamos los datos\n",
        "for year in range(2002, 2024):\n",
        "  os.remove(f\"{root_directory_path}/col_pd_{year}_1km_ASCII_XYZ.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQo1TWpPTvn_"
      },
      "source": [
        "# Land cover data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ8xknDv_hFE"
      },
      "source": [
        "The Intergovernmental Panel on Climate Change (IPCC) provides guidance on reporting areal extent and change of land cover and land use, requiring the use of estimators that neither over or underestimate dynamics to the degree possible, and that have known uncertainties. The maps provided by GLAD do not have these properties. However, the maps can be leveraged to facilitate appropriate probability-based statistical methods in deriving statistically valid areas of forest extent and change. Specifically, the maps may be used as a stratifier in targeting forest extent and/or change by a probability sample. The team at GLAD has demonstrated such approaches using the GLAD forest loss data in sample-based area estimation (Tyukavina et al., ERL, 2018, Turubanova et al., ERL, 2019, and Potapov et al., RSE, 2019, among others).\n",
        "\n",
        "More information [here](https://storage.googleapis.com/earthenginepartners-hansen/GLCLU2000-2020/v2/download.html)\n",
        "\n",
        "Legend [here](https://storage.googleapis.com/earthenginepartners-hansen/GLCLU2000-2020/legend.xlsx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nV2Jsjba3UyT",
        "outputId": "de3b79a5-3be7-41f4-9fff-ad19d67007f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Descargado: ./datasets/land_cover_Colombia_2000_20N_080W.tif\n",
            "Descargado: ./datasets/land_cover_Colombia_2000_10N_080W.tif\n",
            "Descargado: ./datasets/land_cover_Colombia_2000_10N_070W.tif\n",
            "Descargado: ./datasets/land_cover_Colombia_2000_00N_080W.tif\n",
            "Descargado: ./datasets/land_cover_Colombia_2005_20N_080W.tif\n",
            "Descargado: ./datasets/land_cover_Colombia_2005_10N_080W.tif\n",
            "Descargado: ./datasets/land_cover_Colombia_2005_10N_070W.tif\n",
            "Descargado: ./datasets/land_cover_Colombia_2005_00N_080W.tif\n",
            "Descargado: ./datasets/land_cover_Colombia_2010_20N_080W.tif\n",
            "Descargado: ./datasets/land_cover_Colombia_2010_10N_080W.tif\n",
            "Descargado: ./datasets/land_cover_Colombia_2010_10N_070W.tif\n",
            "Descargado: ./datasets/land_cover_Colombia_2010_00N_080W.tif\n",
            "Descargado: ./datasets/land_cover_Colombia_2015_20N_080W.tif\n",
            "Descargado: ./datasets/land_cover_Colombia_2015_10N_080W.tif\n",
            "Descargado: ./datasets/land_cover_Colombia_2015_10N_070W.tif\n",
            "Descargado: ./datasets/land_cover_Colombia_2015_00N_080W.tif\n",
            "Descargado: ./datasets/land_cover_Colombia_2020_20N_080W.tif\n",
            "Descargado: ./datasets/land_cover_Colombia_2020_10N_080W.tif\n",
            "Descargado: ./datasets/land_cover_Colombia_2020_10N_070W.tif\n",
            "Descargado: ./datasets/land_cover_Colombia_2020_00N_080W.tif\n"
          ]
        }
      ],
      "source": [
        "range_values = [(20, 80), (10, 80), (10, 70), ('00', 80)]\n",
        "for year in range(2000, 2021, 5):\n",
        "  for N, W in range_values:\n",
        "    remote_url = f\"https://storage.googleapis.com/earthenginepartners-hansen/GLCLU2000-2020/v2/{year}/{N}N_0{W}W.tif\"\n",
        "    land_cover_path = f\"{root_directory_path}/land_cover_Colombia_{year}_{N}N_0{W}W.tif\"\n",
        "    request.urlretrieve(remote_url, land_cover_path)\n",
        "    print(f\"Descargado: {land_cover_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udQhjBHOCNsu"
      },
      "outputs": [],
      "source": [
        "def get_land_cover(lat, lon, year):\n",
        "  for N, W in range_values:\n",
        "    land_cover_path = f\"{root_directory_path}/land_cover_Colombia_{year}_{N}N_0{W}W.tif\"\n",
        "\n",
        "    with rasterio.open(land_cover_path) as src:\n",
        "      x, y = src.index(lon, lat)\n",
        "      land_cover = src.read(1, window=((y, y + 1), (x, x + 1)))\n",
        "\n",
        "      if len(land_cover) > 0:\n",
        "        if len(land_cover[0]) > 0:\n",
        "          return land_cover[0][0]\n",
        "\n",
        "  return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y6VXkn43eHZ",
        "outputId": "5df6af44-f1d3-4758-e514-432b3fe6f81a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datos desde 2000-01-01 hasta 2004-12-31 descargados\n",
            "Datos desde 2005-01-01 hasta 2009-12-31 descargados\n",
            "Datos desde 2010-01-01 hasta 2014-12-31 descargados\n",
            "Datos desde 2015-01-01 hasta 2019-12-31 descargados\n",
            "Datos desde 2020-01-01 hasta 2024-12-31 descargados\n"
          ]
        }
      ],
      "source": [
        "for year in range(2000, 2021, 5):\n",
        "  land_cover_values = []\n",
        "  land_cover_csv_path = f\"{root_directory_path}/land_cover_Colombia_{year}_{year + 4}.csv\"\n",
        "  min_date, max_date = pd.to_datetime(f\"{year}-01-01\"), pd.to_datetime(f\"{year + 4}-12-31\")\n",
        "\n",
        "  df_tff = df_forest_fire[pd.to_datetime(df_forest_fire['acq_date']) <= max_date]\n",
        "  df_tff = df_tff[min_date <= pd.to_datetime(df_tff['acq_date'])]\n",
        "\n",
        "  lat_values, lon_values = df_tff['latitude'].to_numpy(), df_tff['longitude'].to_numpy()\n",
        "  for lat, lon in zip(lat_values, lon_values):\n",
        "    land_cover = get_land_cover(lat, lon, year)\n",
        "    land_cover_values.append(land_cover)\n",
        "\n",
        "  df_lc_csv = pd.DataFrame({'latitude': lat_values, 'longitude': lon_values, 'land_cover': land_cover_values})\n",
        "  df_lc_csv.to_csv(land_cover_csv_path, index=False)\n",
        "  print(f\"Datos desde {str(min_date.date())} hasta {str(max_date.date())} descargados\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrKwsoc2JSx_"
      },
      "outputs": [],
      "source": [
        "df_land_cover = pd.DataFrame()\n",
        "for year in range(2000, 2021, 5):\n",
        "  land_cover_csv_path = f\"{root_directory_path}/land_cover_Colombia_{year}_{year + 4}.csv\"\n",
        "  df_tlc = pd.read_csv(land_cover_csv_path)\n",
        "  df_land_cover = pd.concat([df_land_cover, df_tlc])\n",
        "\n",
        "df_land_cover.to_csv(f\"{root_directory_path}/land_cover_Colombia.csv\", index=False)\n",
        "\n",
        "# Eliminamos los datos\n",
        "for year in range(2000, 2021, 5):\n",
        "  os.remove(f\"{root_directory_path}/land_cover_Colombia_{year}_{year + 4}.csv\")\n",
        "\n",
        "  for N, W in range_values:\n",
        "    os.remove(f\"{root_directory_path}/land_cover_Colombia_{year}_{N}N_0{W}W.tif\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXfdZbAqdn0y",
        "outputId": "871ab81b-ffac-4626-eadc-38e07a41f9ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./datasets/land_cover_legend_Colombia.xlsx',\n",
              " <http.client.HTTPMessage at 0x285bd58d150>)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "remote_url = f\"https://storage.googleapis.com/earthenginepartners-hansen/GLCLU2000-2020/legend.xlsx\"\n",
        "land_cover_legend_path = f\"{root_directory_path}/land_cover_legend_Colombia.xlsx\"\n",
        "request.urlretrieve(remote_url, land_cover_legend_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "xvoK5CPjLyRj"
      },
      "outputs": [],
      "source": [
        "df_land_cover_legend = pd.read_excel(land_cover_legend_path)\n",
        "df_land_cover_legend.rename(columns={'Unnamed: 2': 'class'}, inplace=True)\n",
        "\n",
        "def set_values(column1, column2, indexes, nan_indexes=[]):\n",
        "    for start_index, end_index in indexes:\n",
        "        total = end_index - start_index + 1\n",
        "        df_land_cover_legend.loc[np.linspace(start_index, end_index, total), column1] = df_land_cover_legend.at[start_index, column2]\n",
        "    \n",
        "    for nan_index in nan_indexes:\n",
        "        df_land_cover_legend.at[nan_index, column1] = np.NAN\n",
        "\n",
        "# Same column\n",
        "set_values('General class', 'General class', [(0, 96), (100, 196), (200, 207)], [97, 197, 208, 242, 245, 251, 255])\n",
        "set_values('class', 'class', [(0, 1), (2, 18), (19, 24), (25, 48), (100, 101), (102, 118), (119, 124), (125, 148)], [49, 149])\n",
        "\n",
        "# Other column\n",
        "set_values('class', 'General class', [(200, 207), (241, 241), (244, 244), (250, 250), (254, 254)])\n",
        "set_values('Sub-class', 'General class', [(241, 241), (244, 244), (250, 250), (254, 254)])\n",
        "\n",
        "df_land_cover_legend.to_csv(f\"{root_directory_path}/land_cover_legend_Colombia.csv\", index=False)\n",
        "os.remove(land_cover_legend_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "lUw1D4CkTx9v",
        "mYviqtW0GDuz",
        "Q-GzYylUf8lp",
        "WAV0R_YDgBen",
        "5OrmyxAWgPpT",
        "E---mq6HTxAs"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
